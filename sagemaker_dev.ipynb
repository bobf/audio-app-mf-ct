{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rk6Sc9PhsWCV"
   },
   "source": [
    "# Audio classification model inference\n",
    "\n",
    "* Model - pretrained fastai2 xresnet18 using fastai2 audio library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N_C3LR2lsWCb"
   },
   "source": [
    "**fastai2_audio**\n",
    "\n",
    "The additional requirements of the fastai2_audio package will be dealt with below, using a clone of the following repo:\n",
    "\n",
    "https://github.com/rbracco/fastai2_audio\n",
    "\n",
    "The demo was run and tested by deploying an SageMaker Notebook instance as per the instructions outlined [here] (https://forums.fast.ai/t/platform-amazon-sagemaker-aws/66020).\n",
    "\n",
    "Note - the above link is only accessible as part of the ongoing fastai course for the time being."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sqkfnPsxvUG7"
   },
   "source": [
    "## INSTALL FASTAI2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "colab_type": "code",
    "id": "SLc5PWxdvYkb",
    "outputId": "6c34bac0-9fbb-4c2f-c0bd-704e647e99f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastai2\n",
      "  Using cached https://files.pythonhosted.org/packages/26/4f/0f61bb0d376eb47c20430639bac4946ca0cffcd7e693fb86698656324f2d/fastai2-0.0.17-py3-none-any.whl\n",
      "Collecting spacy (from fastai2)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/2e/ac00f5c9d01e66cc6ab75eb2a460c9b0dc21ad99a12f810c86a58309e63c/spacy-2.2.4-cp36-cp36m-manylinux1_x86_64.whl (10.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.6MB 4.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from fastai2) (2.20.0)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from fastai2) (0.20.3)\n",
      "Requirement already satisfied: pillow in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from fastai2) (5.1.0)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from fastai2) (1.1.0)\n",
      "Collecting torchvision>=0.5 (from fastai2)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/51/aa2770a70f612ce9a2fc7da3a1a93f9ecf8746788256fed6b691f9b31ca9/torchvision-0.6.0-cp36-cp36m-manylinux1_x86_64.whl (6.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 6.6MB 7.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fastcore (from fastai2)\n",
      "  Using cached https://files.pythonhosted.org/packages/dd/f3/8cd2e1ed981b0ddbe4d56e5d44f52c9e56d27ac7d53c30abb534d10c82c2/fastcore-0.1.17-py3-none-any.whl\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from fastai2) (0.24.2)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from fastai2) (3.0.3)\n",
      "Collecting torch>=1.3.0 (from fastai2)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/70/54e9fb010fe1547bc4774716f11ececb81ae5b306c05f090f4461ee13205/torch-1.5.0-cp36-cp36m-manylinux1_x86_64.whl (752.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 752.0MB 21kB/s  eta 0:00:01  3% |█                               | 23.5MB 49.4MB/s eta 0:00:15    4% |█▋                              | 36.7MB 54.0MB/s eta 0:00:14    7% |██▎                             | 54.7MB 34.9MB/s eta 0:00:20                         | 66.8MB 44.3MB/s eta 0:00:16    19% |██████▍                         | 149.6MB 53.8MB/s eta 0:00:12    24% |████████                        | 186.2MB 29.3MB/s eta 0:00:20    26% |████████▍                       | 195.9MB 36.6MB/s eta 0:00:16    28% |█████████                       | 213.3MB 48.5MB/s eta 0:00:12    29% |█████████▌                      | 222.6MB 26.4MB/s eta 0:00:21    31% |██████████                      | 234.7MB 40.2MB/s eta 0:00:13    34% |███████████▏                    | 261.3MB 48.3MB/s eta 0:00:11    35% |███████████▎                    | 266.0MB 26.4MB/s eta 0:00:19    36% |███████████▌                    | 270.7MB 41.8MB/s eta 0:00:1248.0MB/s eta 0:00:10    47% |███████████████▎                | 359.7MB 62.4MB/s eta 0:00:07    51% |████████████████▍               | 384.3MB 30.5MB/s eta 0:00:13    55% |█████████████████▉              | 419.5MB 33.2MB/s eta 0:00:11    57% |██████████████████▎             | 429.5MB 41.1MB/s eta 0:00:08    61% |███████████████████▉            | 466.2MB 51.3MB/s eta 0:00:06    63% |████████████████████▎           | 476.4MB 43.7MB/s eta 0:00:07    64% |████████████████████▊           | 486.4MB 29.7MB/s eta 0:00:09    81% |██████████████████████████▏     | 616.0MB 26.7MB/s eta 0:00:06    89% |████████████████████████████▋   | 673.0MB 29.2MB/s eta 0:00:03    91% |█████████████████████████████▏  | 685.3MB 25.6MB/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from fastai2) (5.3.1)\n",
      "Collecting fastprogress>=0.1.22 (from fastai2)\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/da/ffd8fe0daf7e679804a32a1e8654ac2988e2ef85937fc1d223e98eee736e/fastprogress-0.2.3-py3-none-any.whl\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from spacy->fastai2) (39.1.0)\n",
      "Collecting plac<1.2.0,>=0.9.6 (from spacy->fastai2)\n",
      "  Downloading https://files.pythonhosted.org/packages/86/85/40b8f66c2dd8f4fd9f09d59b22720cffecf1331e788b8a0cab5bafb353d1/plac-1.1.3-py2.py3-none-any.whl\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy->fastai2)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/6b/e07fad36913879757c90ba03d6fb7f406f7279e11dcefc105ee562de63ea/preshed-3.0.2-cp36-cp36m-manylinux1_x86_64.whl (119kB)\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 38.9MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting tqdm<5.0.0,>=4.38.0 (from spacy->fastai2)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/40/058b12e8ba10e35f89c9b1fdfc2d4c7f8c05947df2d5eb3c7b258019fda0/tqdm-4.46.0-py2.py3-none-any.whl (63kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 32.6MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting wasabi<1.1.0,>=0.4.0 (from spacy->fastai2)\n",
      "  Downloading https://files.pythonhosted.org/packages/21/e1/e4e7b754e6be3a79c400eb766fb34924a6d278c43bb828f94233e0124a21/wasabi-0.6.0-py3-none-any.whl\n",
      "Collecting catalogue<1.1.0,>=0.0.7 (from spacy->fastai2)\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/f9/9a5658e2f56932e41eb264941f9a2cb7f3ce41a80cb36b2af6ab78e2f8af/catalogue-1.0.0-py2.py3-none-any.whl\n",
      "Collecting numpy>=1.15.0 (from spacy->fastai2)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/27/e35e7c6e6a52fab9fcc64fc2b20c6b516eba930bb02b10ace3b38200d3ab/numpy-1.18.4-cp36-cp36m-manylinux1_x86_64.whl (20.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 20.2MB 1.7MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting cymem<2.1.0,>=2.0.2 (from spacy->fastai2)\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/b5/3e1714ebda8fd7c5859f9b216e381adc0a38b962f071568fd00d67e1b1ca/cymem-2.0.3-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting blis<0.5.0,>=0.4.0 (from spacy->fastai2)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/19/f95c75562d18eb27219df3a3590b911e78d131b68466ad79fdf5847eaac4/blis-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.7MB 17.9MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting murmurhash<1.1.0,>=0.28.0 (from spacy->fastai2)\n",
      "  Downloading https://files.pythonhosted.org/packages/a6/e6/63f160a4fdf0e875d16b28f972083606d8d54f56cd30cb8929f9a1ee700e/murmurhash-1.0.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting srsly<1.1.0,>=1.0.2 (from spacy->fastai2)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/9a/70bd934dd4d25545c9aa6c8cd4edbac2a33ba9c915439a9209b69f0ec0ad/srsly-1.0.2-cp36-cp36m-manylinux1_x86_64.whl (185kB)\n",
      "\u001b[K    100% |████████████████████████████████| 194kB 42.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting thinc==7.4.0 (from spacy->fastai2)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/ed/8e4559f1090fb05c0fa982a8a2caaa315967e7b460652be479d13fd1c813/thinc-7.4.0-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.2MB 23.6MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests->fastai2) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests->fastai2) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests->fastai2) (2.6)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests->fastai2) (1.24.3)\n",
      "Collecting dataclasses>='0.7'; python_version < \"3.7\" (from fastcore->fastai2)\n",
      "  Downloading https://files.pythonhosted.org/packages/e1/d2/6f02df2616fd4016075f60157c7a0452b38d8f7938ae94343911e0fb0b09/dataclasses-0.7-py3-none-any.whl\n",
      "Requirement already satisfied: pytz>=2011k in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from pandas->fastai2) (2018.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from pandas->fastai2) (2.7.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from matplotlib->fastai2) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from matplotlib->fastai2) (2.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from matplotlib->fastai2) (1.0.1)\n",
      "Requirement already satisfied: future in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from torch>=1.3.0->fastai2) (0.17.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai2) (1.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas->fastai2) (1.11.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai2) (3.0.0)\n",
      "\u001b[31mamazonei-mxnet 1.5.1 has requirement numpy<1.15.0,>=1.8.2, but you'll have numpy 1.18.4 which is incompatible.\u001b[0m\n",
      "Installing collected packages: plac, cymem, murmurhash, preshed, tqdm, wasabi, catalogue, numpy, blis, srsly, thinc, spacy, torch, torchvision, dataclasses, fastcore, fastprogress, fastai2\n",
      "  Found existing installation: numpy 1.14.6\n",
      "    Uninstalling numpy-1.14.6:\n",
      "      Successfully uninstalled numpy-1.14.6\n",
      "Successfully installed blis-0.4.1 catalogue-1.0.0 cymem-2.0.3 dataclasses-0.7 fastai2-0.0.17 fastcore-0.1.17 fastprogress-0.2.3 murmurhash-1.0.2 numpy-1.18.4 plac-1.1.3 preshed-3.0.2 spacy-2.2.4 srsly-1.0.2 thinc-7.4.0 torch-1.5.0 torchvision-0.6.0 tqdm-4.46.0 wasabi-0.6.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#In SageMaker we need to run this as a  shell commands i.e. with '!' infront of 'pip'\n",
    "!pip install fastai2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ycpfB-G4sWCd"
   },
   "source": [
    "## Install the fastai2_audio library\n",
    "\n",
    "We need to install the fastai2_audio library to the local kernel/environment for the analysis\n",
    "\n",
    "Note the lack of `!pip` (that install to the root env) but rather standard `pip` (that installs to the current kernl/env)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "B7ogGfTcsWCf",
    "outputId": "8b029a0c-1065-4c04-bc43-4877420e3eea",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/mikful/fastai2_audio.git\n",
      "  Cloning https://github.com/mikful/fastai2_audio.git to /tmp/pip-req-build-ixpjmniv\n",
      "  Running command git clone -q https://github.com/mikful/fastai2_audio.git /tmp/pip-req-build-ixpjmniv\n",
      "Collecting torchaudio\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/7d/8e01e21175dd2c9bb1b7e014e0c56cdd02618e2db5bebb4f52f6fdf253cb/torchaudio-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (3.2MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2MB 6.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (from fastai2-audio==0.0.1) (0.6.3)\n",
      "Collecting soundfile\n",
      "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: fastai2 in /usr/local/lib/python3.6/dist-packages (from fastai2-audio==0.0.1) (0.0.17)\n",
      "Collecting colorednoise\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/3e/85645bcaa5ba6003c6e3c650fe23c6352f7aa4a36eb1d700f3609e52963e/colorednoise-1.1.1.tar.gz\n",
      "Requirement already satisfied: torch==1.5.0 in /usr/local/lib/python3.6/dist-packages (from torchaudio->fastai2-audio==0.0.1) (1.5.0+cu101)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->fastai2-audio==0.0.1) (1.4.1)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->fastai2-audio==0.0.1) (4.4.2)\n",
      "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa->fastai2-audio==0.0.1) (0.14.1)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa->fastai2-audio==0.0.1) (0.22.2.post1)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->fastai2-audio==0.0.1) (2.1.8)\n",
      "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa->fastai2-audio==0.0.1) (0.48.0)\n",
      "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa->fastai2-audio==0.0.1) (0.2.2)\n",
      "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa->fastai2-audio==0.0.1) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa->fastai2-audio==0.0.1) (1.18.3)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile->fastai2-audio==0.0.1) (1.14.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai2-audio==0.0.1) (2.23.0)\n",
      "Requirement already satisfied: fastprogress>=0.1.22 in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai2-audio==0.0.1) (0.2.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai2-audio==0.0.1) (3.13)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai2-audio==0.0.1) (7.0.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai2-audio==0.0.1) (1.0.3)\n",
      "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai2-audio==0.0.1) (2.2.4)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai2-audio==0.0.1) (3.2.1)\n",
      "Requirement already satisfied: fastcore in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai2-audio==0.0.1) (0.1.17)\n",
      "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai2-audio==0.0.1) (0.6.0+cu101)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.0->torchaudio->fastai2-audio==0.0.1) (0.16.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa->fastai2-audio==0.0.1) (46.1.3)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa->fastai2-audio==0.0.1) (0.31.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile->fastai2-audio==0.0.1) (2.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2->fastai2-audio==0.0.1) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2->fastai2-audio==0.0.1) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2->fastai2-audio==0.0.1) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2->fastai2-audio==0.0.1) (3.0.4)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai2->fastai2-audio==0.0.1) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai2->fastai2-audio==0.0.1) (2.8.1)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai2-audio==0.0.1) (7.4.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai2-audio==0.0.1) (0.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai2-audio==0.0.1) (0.6.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai2-audio==0.0.1) (1.0.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai2-audio==0.0.1) (1.1.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai2-audio==0.0.1) (2.0.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai2-audio==0.0.1) (1.0.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai2-audio==0.0.1) (3.0.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai2-audio==0.0.1) (1.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai2-audio==0.0.1) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2->fastai2-audio==0.0.1) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2->fastai2-audio==0.0.1) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2->fastai2-audio==0.0.1) (2.4.7)\n",
      "Requirement already satisfied: dataclasses>='0.7'; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastcore->fastai2->fastai2-audio==0.0.1) (0.7)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai2->fastai2-audio==0.0.1) (1.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai2->fastai2-audio==0.0.1) (3.1.0)\n",
      "Building wheels for collected packages: fastai2-audio, colorednoise\n",
      "  Building wheel for fastai2-audio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for fastai2-audio: filename=fastai2_audio-0.0.1-cp36-none-any.whl size=15764 sha256=e41264d5edbedd90fafa779fe291ba0ca909a4336e8c40ab99ed247794a57962\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-bo7y5bty/wheels/21/78/26/cd4f9a6750539feda2dab7cbe11110f74ebadaff3c863f8b51\n",
      "  Building wheel for colorednoise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for colorednoise: filename=colorednoise-1.1.1-cp36-none-any.whl size=3958 sha256=424728e1886da2a91ba8b05ba117d436480ab6899de627268c6d4849ab6f5145\n",
      "  Stored in directory: /root/.cache/pip/wheels/84/be/f3/3e7e1c80ebab3f6f0dbd3e34e787b902d2280d66706485fef4\n",
      "Successfully built fastai2-audio colorednoise\n",
      "Installing collected packages: torchaudio, soundfile, colorednoise, fastai2-audio\n",
      "Successfully installed colorednoise-1.1.1 fastai2-audio-0.0.1 soundfile-0.10.3.post1 torchaudio-0.5.0\n"
     ]
    }
   ],
   "source": [
    "#In Colab we need to run this as a shell command i.e. with '!' infront of 'pip'\n",
    "\n",
    "!pip install git+https://github.com/mikful/fastai2_audio.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F2gUqCfWsWCm"
   },
   "outputs": [],
   "source": [
    "# Solving an OSError problem with Librosa SoundFile dependency (libsndfile)\n",
    "# SageMaker/GCP Only\n",
    "\n",
    "# !conda install -c conda-forge libsndfile --yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hWCdC9SesWCs"
   },
   "source": [
    "## Load Pretrained Model (from Colab) and Perform Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CjNZwPO-sWCu"
   },
   "outputs": [],
   "source": [
    "from fastai2.vision.all import *\n",
    "from fastai2_audio.core import *\n",
    "from fastai2_audio.augment import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x(r): return r['fname']\n",
    "def get_y(r): return r['labels'].split(',') # split labels on ','\n",
    "dblock = DataBlock(get_x = get_x, get_y = get_y)\n",
    "dsets = dblock.datasets(df_combined)\n",
    "dsets.train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBMelSpec = SpectrogramTransformer(mel=True, to_db=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = AudioConfig.BasicMelSpectrogram()\n",
    "aud2spec = AudioToSpec.from_cfg(cfg)\n",
    "aud2spec.settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's change the settings to see the impact\n",
    "aud2spec = DBMelSpec(sample_rate= 16000, f_max=None, f_min=20, n_mels=128, n_fft=1024, hop_length=128, top_db=90)\n",
    "aud2spec.settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_tfms = [RemoveSilence(), CropSignal(3000, pad_mode='Repeat'), aud2spec, MaskTime(num_masks=1, size=100), MaskFreq(num_masks=1, size=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs redefining fors test only\n",
    "\n",
    "dblock = DataBlock(blocks=(AudioBlock, MultiCategoryBlock),\n",
    "                    splitter=RandomSplitter(),\n",
    "                    get_x=get_x,\n",
    "                    get_y=get_y,\n",
    "                    item_tfms = item_tfms)\n",
    "\n",
    "# dsets = dblock.datasets(df_curated)\n",
    "dsets = dblock.datasets(df_combined)\n",
    "dsets.train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(df_combined, bs=32) # bs= batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load pretrained 1-channel xresnet18 with multi-accuracy\n",
    "\n",
    "# Custom cnn model created from pretrained xresnet18 (smaller model for inference speed)\n",
    "# 1 input channel and 80 output nodes\n",
    "# torch.nn.BCEWithLogitsLoss() = Binary Cross Entropy Loss from pytorch\n",
    "# accuracy_multi for multi label\n",
    "\n",
    "model = create_cnn_model(xresnet18, n_in=1, n_out=80, pretrained=True)\n",
    "\n",
    "learn = Learner(dls, model, BCEWithLogitsLossFlat(), metrics=accuracy_multi) # pass custom model to Learner\n",
    "\n",
    "learn.load('xresnet50-stage-2-model-finetuned.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test file path in S3\n",
    "df_fname = '../data/test/' + df_fnames.fname\n",
    "print(df_fname)\n",
    "\n",
    "#create new dataloaders\n",
    "dl = learn.dls.test_dl(df_fnames)\n",
    "    \n",
    "# predict using tta    \n",
    "preds, targs = learn.tta(dl=dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xz0d72WcsWGp"
   },
   "source": [
    "## Export the model and upload to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1SP0fhq6sWGq"
   },
   "source": [
    "Now that we have trained our model we will export it using the learner method `export()` and upload the exported model to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g7YXuARWsWGs"
   },
   "outputs": [],
   "source": [
    "learn.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "18UaCxaKsWGw"
   },
   "source": [
    "Now let's create a tarfile for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8K0jE1znsWGz"
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "with tarfile.open(path/'model.tar.gz', 'w:gz') as f:\n",
    "    f.add(path/'export.pkl', arcname='model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cIoEqpzxsWG4"
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GoPK3YYysWG8"
   },
   "outputs": [],
   "source": [
    "prefix = 'audio-app-mf-ct'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "leG1Y1Q9sWHA"
   },
   "source": [
    "Now we will upload the model to the default S3 bucket for sagemaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CpwBMVogsWHB"
   },
   "outputs": [],
   "source": [
    "model_location = sess.upload_data(str(path/'model.tar.gz'), key_prefix=prefix)\n",
    "model_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ae8WqB6OsWHF"
   },
   "source": [
    "## Script for model inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F6sQdVtrsWHG"
   },
   "source": [
    "SageMaker invokes the main function defined within your training script for training. When deploying your trained model to an endpoint, the `model_fn()` is called to determine how to load your trained model. The `model_fn()` along with a few other functions list below are called to enable predictions on SageMaker.\n",
    "\n",
    "### [Predicting Functions](https://github.com/aws/sagemaker-pytorch-containers/blob/master/src/sagemaker_pytorch_container/serving.py)\n",
    "* `model_fn(model_dir)` - loads your model.\n",
    "* `input_fn(serialized_input_data, content_type)` - deserializes predictions to predict_fn.\n",
    "* `output_fn(prediction_output, accept)` - serializes predictions from predict_fn.\n",
    "* `predict_fn(input_data, model)` - calls a model on data deserialized in input_fn.\n",
    "\n",
    "Here is the full code in a file `serve.py` showing implementations of the 4 key functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1yGJoE9bsWHH"
   },
   "outputs": [],
   "source": [
    "!pygmentize scripts/serve.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4_p0MGBxsWHL"
   },
   "source": [
    "## Deploy locally to test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jYT5WychsWHM"
   },
   "source": [
    "Before deploying to Amazon SageMaker we want to verify that the endpoint is working properly. The Amazon SageMaker Python SDK allows us to deploy locally to the Notebook instance using Docker. We will create the model then specify the parameter `instance_type` to be `local` telling the SDK to deploy locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "blQEchj_sWHN"
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "model = PyTorchModel(model_data=model_location,\n",
    "                     role=role,\n",
    "                     framework_version='1.4.0',\n",
    "                     entry_point='serve.py', \n",
    "                     source_dir='scripts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bWgN9-YUsWHQ"
   },
   "source": [
    "Now that we have created the model we will deploy locally to test. It may take a while to run the first time as we need to download a Docker image to our notebook instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7TKQ_WACsWHR"
   },
   "outputs": [],
   "source": [
    "predictor = model.deploy(initial_instance_count=1, instance_type='local')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6uOjLVQksWHZ"
   },
   "source": [
    "Now we can test out our endpoint. We will download a cat images from the internet and save locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jj9OEL2bsWHa"
   },
   "outputs": [],
   "source": [
    "! [ -d tmp ] || mkdir tmp\n",
    "! wget -q -O tmp/british-shorthair.jpg https://cdn1-www.cattime.com/assets/uploads/2011/12/file_2744_british-shorthair-460x290-460x290.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_jDltlVYsWHe"
   },
   "outputs": [],
   "source": [
    "img = Image.open('tmp/british-shorthair.jpg')\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YmCko7bfsWHh"
   },
   "source": [
    "Now we can call our local endpoint to ensure it is working and provides us the correct result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CqWJBsF4sWHi"
   },
   "outputs": [],
   "source": [
    "from sagemaker.predictor import json_serializer, json_deserializer\n",
    "\n",
    "predictor.accept = 'application/json'\n",
    "predictor.content_type = 'application/json'\n",
    "\n",
    "predictor.serializer = json_serializer\n",
    "predictor.deserializer = json_deserializer\n",
    "\n",
    "response = predictor.predict( { \"url\": \"https://cdn1-www.cattime.com/assets/uploads/2011/12/file_2744_british-shorthair-460x290-460x290.jpg\" })\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcaEoVm4sWHm"
   },
   "source": [
    "Once you are happy that the endpoint is working suceessully you can shut it down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1LzkT9NDsWHn"
   },
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VlbLIQoQsWHr"
   },
   "source": [
    "## Deploy to SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qlyi0ZmzsWHt"
   },
   "source": [
    "Once we have verified that the script is working successfully on our locally deployed endpoint we can deploy our model to Amazon SageMaker so that it can be used in a production application. The code is almost exactly the same as deploying locally except that when we call `model.deploy()` we will change the instance type to an Amazon SageMaker valid instance type (e.g. `ml.m5.xlarge`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hfZqQGEQsWHw"
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "model = PyTorchModel(model_data=model_location,\n",
    "                     role=role,\n",
    "                     framework_version='1.4.0',\n",
    "                     entry_point='serve.py', \n",
    "                     source_dir='scripts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LiNTlWaksWHz"
   },
   "source": [
    "Now let's deploy our SageMaker endpoint. It will take a few min to provision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UrEsA37asWH2"
   },
   "outputs": [],
   "source": [
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.m5.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3HAXGIxUsWH6"
   },
   "outputs": [],
   "source": [
    "img = Image.open('tmp/british-shorthair.jpg')\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l1FCkQ1isWH9"
   },
   "source": [
    "Now let's test our remote endpoint running on SageMaker hosting services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OqTrUNPnsWH9"
   },
   "outputs": [],
   "source": [
    "from sagemaker.predictor import json_serializer, json_deserializer\n",
    "\n",
    "predictor.accept = 'application/json'\n",
    "predictor.content_type = 'application/json'\n",
    "\n",
    "predictor.serializer = json_serializer\n",
    "predictor.deserializer = json_deserializer\n",
    "\n",
    "response = predictor.predict( { \"url\": \"https://cdn1-www.cattime.com/assets/uploads/2011/12/file_2744_british-shorthair-460x290-460x290.jpg\" })\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aFrXfbOlsWIB"
   },
   "source": [
    "## Optional: delete endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lkl5ySrQsWIC"
   },
   "source": [
    "If you do not want to keep the endpoint up and running then remember to delete it to avoid incurring further costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hH-iPvGssWID"
   },
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "khBWm2CXsWIG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B7Q8QPciaNhQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "g5ZLivT8Ie_M",
    "F6sQdVtrsWHG",
    "4_p0MGBxsWHL",
    "VlbLIQoQsWHr",
    "aFrXfbOlsWIB"
   ],
   "include_colab_link": true,
   "name": "model_colab dev.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
